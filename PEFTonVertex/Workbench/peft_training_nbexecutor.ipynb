{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a06eccf-c27e-40b6-bef2-24634e302a20",
   "metadata": {},
   "source": [
    "## Write training code here and Click \"Execute\" for a workbench execute job\n",
    "- Use custom container built in Cloud Build and stored in Artifact Registry\n",
    "- Cloud Build command: gcloud builds submit --config cloud-build.yaml .\n",
    "- input and output directory can be /gcs/bucket_name/folder for Cloud Storage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd36dd-023d-482a-a322-3b2a88f358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
    "INSTANCE_DIR=\"/gcs/bucket_name/input_dog\"\n",
    "OUTPUT_DIR=\"/gcs/bucket_name/peft/workbench_dog_lora_output\"\n",
    "PROMPT = \"a photo of sks dog\"\n",
    "CLASS_PROMPT = \"a photo of dog\"\n",
    "\n",
    "! accelerate launch train_dreambooth.py \\\n",
    "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "    --instance_data_dir=$INSTANCE_DIR \\\n",
    "    --output_dir=$OUTPUT_DIR \\\n",
    "    --train_text_encoder \\\n",
    "    --with_prior_preservation \\\n",
    "    --prior_loss_weight=1 \\\n",
    "    --num_class_images=50 \\\n",
    "    --class_prompt=\"$CLASS_PROMPT\" \\\n",
    "    --class_data_dir=$OUTPUT_DIR/class_data \\\n",
    "    --instance_prompt=\"$PROMPT\" \\\n",
    "    --use_lora \\\n",
    "    --lora_r=4 \\\n",
    "    --lora_alpha=4 \\\n",
    "    --lora_bias=none \\\n",
    "    --lora_dropout=0.0 \\\n",
    "    --lora_text_encoder_r=4 \\\n",
    "    --lora_text_encoder_alpha=4 \\\n",
    "    --lora_text_encoder_bias=none \\\n",
    "    --lora_text_encoder_dropout=0.0 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --resolution=512 \\\n",
    "    --train_batch_size=1 \\\n",
    "    --use_8bit_adam \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --learning_rate=1e-4 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434a810-77f1-4ea1-b2f0-c0ccdd5b1964",
   "metadata": {},
   "source": [
    "## Test the generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c90c83-cb29-419a-a355-f214d1d09fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import gradio as gr\n",
    "import PIL.Image\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraModel, LoraConfig, set_peft_model_state_dict\n",
    "\n",
    "\n",
    "class InferencePipeline:\n",
    "    def __init__(self):\n",
    "        self.pipe = None\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.weight_path = None\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.weight_path = None\n",
    "        del self.pipe\n",
    "        self.pipe = None\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_lora_weight_path(name: str) -> pathlib.Path:\n",
    "        curr_dir = pathlib.Path(__file__).parent\n",
    "        return curr_dir / name, curr_dir / f'{name.replace(\".pt\", \"_config.json\")}'\n",
    "\n",
    "    def load_and_set_lora_ckpt(self, pipe, weight_path, config_path, dtype):\n",
    "        with open(config_path, \"r\") as f:\n",
    "            lora_config = json.load(f)\n",
    "        lora_checkpoint_sd = torch.load(weight_path, map_location=self.device)\n",
    "        unet_lora_ds = {k: v for k, v in lora_checkpoint_sd.items() if \"text_encoder_\" not in k}\n",
    "        text_encoder_lora_ds = {\n",
    "            k.replace(\"text_encoder_\", \"\"): v for k, v in lora_checkpoint_sd.items() if \"text_encoder_\" in k\n",
    "        }\n",
    "        unet_config = LoraConfig(**lora_config[\"peft_config\"])\n",
    "        pipe.unet = LoraModel(unet_config, pipe.unet)\n",
    "        set_peft_model_state_dict(pipe.unet, unet_lora_ds)\n",
    "\n",
    "        if \"text_encoder_peft_config\" in lora_config:\n",
    "            text_encoder_config = LoraConfig(**lora_config[\"text_encoder_peft_config\"])\n",
    "            pipe.text_encoder = LoraModel(text_encoder_config, pipe.text_encoder)\n",
    "            set_peft_model_state_dict(pipe.text_encoder, text_encoder_lora_ds)\n",
    "\n",
    "        if dtype in (torch.float16, torch.bfloat16):\n",
    "            pipe.unet.half()\n",
    "            pipe.text_encoder.half()\n",
    "\n",
    "        pipe.to(self.device)\n",
    "        return pipe\n",
    "\n",
    "    def load_pipe(self, model_id: str, lora_filename: str) -> None:\n",
    "        weight_path, config_path = self.get_lora_weight_path(lora_filename)\n",
    "        if weight_path == self.weight_path:\n",
    "            return\n",
    "\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(self.device)\n",
    "        pipe = pipe.to(self.device)\n",
    "        pipe = self.load_and_set_lora_ckpt(pipe, weight_path, config_path, torch.float16)\n",
    "        self.pipe = pipe\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        base_model: str,\n",
    "        lora_weight_name: str,\n",
    "        prompt: str,\n",
    "        negative_prompt: str,\n",
    "        seed: int,\n",
    "        n_steps: int,\n",
    "        guidance_scale: float,\n",
    "    ) -> PIL.Image.Image:\n",
    "        if not torch.cuda.is_available():\n",
    "            raise gr.Error(\"CUDA is not available.\")\n",
    "\n",
    "        self.load_pipe(base_model, lora_weight_name)\n",
    "\n",
    "        generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "        out = self.pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=n_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            negative_prompt=negative_prompt if negative_prompt else None,\n",
    "        )  # type: ignore\n",
    "        return out.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e74035-d456-45d0-93e8-edd414a6d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = InferencePipeline()\n",
    "image = pipe.run(base_model=\"runwayml/stable-diffusion-v1-5\",lora_weight_name=f\"{OUTPUT_DIR}/{PROMPT}_lora.pt\",prompt=\"a photo of sks dog in the forest\", negative_prompt=\"\",n_steps=50,guidance_scale=7.5, seed=1)\n",
    "image.save(f\"{OUTPUTD_DIR}/test_dog.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
